{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax (1D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add the parent directory of the current notebook to sys.path\n",
    "cur_dir = Path().resolve()\n",
    "parent_dir = cur_dir.parent\n",
    "sys.path += [str(parent_dir), str(cur_dir)]\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from utils import cdiv, get_sig, load_cuda, profile_kernel\n",
    "from collections import namedtuple\n",
    "from softmax_py import  softmax_py\n",
    "\n",
    "def test_allclose(kernels):\n",
    "    D = 1024\n",
    "    V_test = torch.randn(D).contiguous().cuda()\n",
    "    O_torch = torch.softmax(V_test,  dim=0)\n",
    "    for kernel_name, kernel_data in kernels.items():\n",
    "        if kernel_name!=\"torch\":\n",
    "            module, fname = kernel_data[\"module\"], kernel_data[\"fname\"]\n",
    "            O = getattr(module, fname)(V_test)\n",
    "            if not torch.allclose(O, O_torch, atol=1e-4):\n",
    "                raise ValueError(f\"{kernel_name=} failed:\\n\\n {O[:10]=}, {O_torch[:10]=}\")\n",
    "            print(f\"{kernel_name=} agrees with torch softmax\")\n",
    "        \n",
    "\n",
    "\n",
    "def profile_kernels(kernels):\n",
    "    test_allclose(kernels)\n",
    "    for kernel_name, kernel_data in kernels.items():\n",
    "        print(f\"Profiling: {kernel_name}\")\n",
    "        profile_kernel(kernel_data[\"module\"], kernel_data[\"fname\"], *kernel_data[\"args\"], **kernel_data[\"kwargs\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Python cuda looking implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V_small = torch.randn(32, dtype=torch.float32).contiguous().cuda()\n",
    "O = softmax_py(V_small)\n",
    "O_torch = torch.softmax(V_small, dim=0)\n",
    "torch.allclose(O, O_torch, atol=1e-4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_modules(kernels):\n",
    "    for kernel_name, kernel_data in kernels.items():\n",
    "\n",
    "        fname = kernel_data[\"fname\"]\n",
    "        cuda_source = Path(kernel_data[\"cuda_source_path\"]).read_text()\n",
    "        cpp_source = get_sig(fname, cuda_source)\n",
    "        module = load_cuda(cuda_source, cpp_source, funcs=[fname])\n",
    "        kernel_data[\"module\"] = module\n",
    "\n",
    "\n",
    "def get_softmax_modules(kernels):\n",
    "    get_modules(kernels)\n",
    "    kernels[\"torch\"] = {\n",
    "        \"module\": torch,\n",
    "        \"fname\": \"softmax\",\n",
    "    }\n",
    "\n",
    "def add_args_kwargs(kernels, *args, **kwargs):\n",
    "    for kernel_name, kernel_data in kernels.items():\n",
    "        kernel_data[\"args\"]= args\n",
    "        if kernel_name == \"torch\":\n",
    "            kernel_data[\"kwargs\"] = kwargs\n",
    "        else: kernel_data[\"kwargs\"] = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 1024*1 +5\n",
    "V = torch.randn(D, dtype=torch.float32).contiguous().cuda()\n",
    "\n",
    "kernels = {\n",
    "    \"softmax_naive\": dict(cuda_source_path = \"./softmax_naive.cu\", fname = \"softmax_naive\"),\n",
    "    \"softmax_fast\": dict(cuda_source_path = \"./softmax_fast.cu\", fname = \"softmax_fast\"),\n",
    "    \"softmax_tiled\": dict(cuda_source_path = \"./softmax_tiled.cu\", fname = \"softmax_tiled\"),\n",
    "}\n",
    "get_softmax_modules(kernels)\n",
    "add_args_kwargs(kernels, V, dim=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel_name='softmax_naive' agrees with torch softmax\n",
      "kernel_name='softmax_fast' agrees with torch softmax\n",
      "kernel_name='softmax_tiled' agrees with torch softmax\n",
      "Profiling: softmax_naive\n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                     Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg    # of Calls  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "              aten::zeros         1.89%      12.960us        92.66%     636.629us     636.629us             1  \n",
      "              aten::empty         4.67%      32.080us        43.12%     296.214us     296.214us             1  \n",
      "             Unrecognized        38.45%     264.134us        38.45%     264.134us     264.134us             1  \n",
      "              aten::zero_         0.74%       5.071us        47.66%     327.455us     327.455us             1  \n",
      "              aten::fill_         1.38%       9.470us        46.92%     322.384us     322.384us             1  \n",
      "         cudaLaunchKernel        52.34%     359.575us        52.34%     359.575us     179.787us             2  \n",
      "    cudaDeviceSynchronize         0.54%       3.741us         0.54%       3.741us       3.741us             1  \n",
      "-------------------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 687.031us\n",
      "\n",
      "Profiling: softmax_fast\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: invalid configuration argument\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mprofile_kernels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernels\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 24\u001b[39m, in \u001b[36mprofile_kernels\u001b[39m\u001b[34m(kernels)\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kernel_name, kernel_data \u001b[38;5;129;01min\u001b[39;00m kernels.items():\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mProfiling: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkernel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     \u001b[43mprofile_kernel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkernel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodule\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfname\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mkernel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43margs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkernel_data\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mkwargs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Workspace/cuda-examples/src/utils/cuda.py:28\u001b[39m, in \u001b[36mprofile_kernel\u001b[39m\u001b[34m(module, fname, *args, **kwargs)\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprofile_kernel\u001b[39m(module, fname, *args, **kwargs):\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n\u001b[32m     27\u001b[39m                 with_stack=\u001b[38;5;28;01mTrue\u001b[39;00m, record_shapes=\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m prof:\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m         \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28mprint\u001b[39m(prof.key_averages().table(sort_by=\u001b[33m\"\u001b[39m\u001b[33mcuda_time_total\u001b[39m\u001b[33m\"\u001b[39m, row_limit=\u001b[32m20\u001b[39m))\n",
      "\u001b[31mRuntimeError\u001b[39m: CUDA error: invalid configuration argument\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "profile_kernels(kernels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O = getattr(module, fname)(V)\n",
    "# O_torch = torch.softmax(V,  dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 20\n",
    "# getattr(module, fname)(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26.7 μs ± 9.2 μs per loop (mean ± std. dev. of 7 runs, 20 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n 20\n",
    "torch.softmax(V,  dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_kernel(torch, \"softmax\", V,  dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_kernel(module, \"softmax\", V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda_source_path = \"./softmax.cu\"\n",
    "# fname = \"softmax_tiled\"\n",
    "# cuda_source = Path(cuda_source_path).read_text()\n",
    "# cpp_source = get_sig(fname, cuda_source)\n",
    "# module = load_cuda(cuda_source, cpp_source, funcs=[fname])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D = 2048**2\n",
    "# V = torch.randn(D).contiguous().cuda()\n",
    "# O = getattr(module, fname)(V)\n",
    "# O_torch = torch.softmax(V,  dim=0)\n",
    "# assert torch.allclose(O, O_torch, atol=1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 20\n",
    "# getattr(module, fname)(V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 20\n",
    "# torch.softmax(V,  dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO\n",
    "setup the profiling to get info on dram+warps etc (lesson 8?)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
